{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "\n",
    "#Make sure you have chrome webdriver installed\n",
    "#If not, go to your chrome browser and type about::\n",
    "#That would give you  the version number then google \"chrome web driver version x\" and download it\n",
    "#Store it in a folder called \"Driver\". The \"Driver\" folder must be in the same folder as this file.\n",
    "\n",
    "#This is searching for the webdriver in your folder\n",
    "browser = webdriver.Chrome('Driver/chromedriver.exe')\n",
    "browser.get('https://www.linkedin.com/uas/login')\n",
    "username = '' #Provide your own\n",
    "password = '' #Provide your own\n",
    "elementID = browser.find_element(By.ID,'username')\n",
    "elementID.send_keys(username)\n",
    "elementID = browser.find_element(By.ID,'password')\n",
    "elementID.send_keys(password)\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = [''] #List of URL's, provide your own. Must be strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_scrap2(url):\n",
    "    #First we scrap all the details on the main page\n",
    "    #Then we check the attributes for whom the external buttons exist\n",
    "    #The attributes without external buttones, those elements are extracted\n",
    "    #Then we visit the external sites\n",
    "\n",
    "    browser.get(url)\n",
    "    src = browser.page_source\n",
    "    soup = bs(src)\n",
    "\n",
    "    name = []\n",
    "    location = []\n",
    "    header = []\n",
    "    connection = []\n",
    "    about =[]\n",
    "    today = [date.today()]\n",
    "    exp_button = False\n",
    "\n",
    "    #STEP 1 : Acquire all data on main page\n",
    "    #ABOUT TAG\n",
    "\n",
    "    #The ember 202 thing was geting different results for different profiles, I simply replaced it to the below div tag to make it better\n",
    "    if bool(soup.find('div', class_ = \"pv-shared-text-with-see-more t-14 t-normal t-black display-flex align-items-center\")) == True:\n",
    "        about_tag = soup.find('div', class_ = \"pv-shared-text-with-see-more t-14 t-normal t-black display-flex align-items-center\")\n",
    "    else:\n",
    "        about_tag = ''\n",
    "\n",
    "    if about_tag == \"\":\n",
    "        about.append(\"Not given\")\n",
    "    else:\n",
    "        about.append(about_tag.text.strip())\n",
    "\n",
    "    #NAME TAG\n",
    "\n",
    "    name_tag = soup.find('h1', class_ = 'text-heading-xlarge inline t-24 v-align-middle break-words')\n",
    "    name.append(name_tag.text)\n",
    "\n",
    "    #LOCATION TAG\n",
    "    location_tag = soup.find('span', class_ = 'text-body-small inline t-black--light break-words')\n",
    "    location.append(location_tag.text.rstrip().strip())\n",
    "\n",
    "    #HEADER TAG\n",
    "    header_tag = soup.find('div', class_ = 'text-body-medium break-words')\n",
    "    if bool(header_tag) == True:\n",
    "        header.append(header_tag.text.lstrip().rstrip())\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #STEP - 2 : Check if external buttons exist\n",
    "\n",
    "    x = soup.findAll('section', class_ = \"artdeco-card ember-view break-words pb3 mt4\")\n",
    "    exp_tag = \"\"\n",
    "    ed_tag = \"\"\n",
    "    cert_tag = \"\"\n",
    "    #First we extract the respective div tags which contain information about the needed attributes\n",
    "    for i in x:\n",
    "        if i.div.attrs['id']=='education':\n",
    "            ed_tag = i.find('div', class_ = \"pvs-list__outer-container\")\n",
    "\n",
    "        if i.div.attrs['id']==\"experience\":\n",
    "            exp_tag =  i.find('div', class_ = \"pvs-list__outer-container\") \n",
    "\n",
    "        if i.div.attrs['id']==\"licenses_and_certifications\":\n",
    "            cert_tag = i.find('div', class_ = \"pvs-list__outer-container\")\n",
    "\n",
    "    #Checking the buttons\n",
    "\n",
    "    #Based on previously obtained tags, we check if those buttons exist or not\n",
    "    #Experience tag\n",
    "    try: \n",
    "        if re.findall(r'See all .+',exp_tag.find('span', class_ = \"pvs-navigation__text\").text.strip()):\n",
    "            exp_button = True\n",
    "    except:\n",
    "        exp_button = False\n",
    "\n",
    "    #Education tag\n",
    "    try: \n",
    "        if re.findall(r'See all .+',ed_tag.find('span', class_ = \"pvs-navigation__text\").text.strip()):\n",
    "            ed_button = True\n",
    "    except:\n",
    "        ed_button = False\n",
    "\n",
    "    #License tag\n",
    "    try: \n",
    "        if re.findall(r'See all .+',cert_tag.find('span', class_ = \"pvs-navigation__text\").text.strip()):\n",
    "            cert_button = True\n",
    "    except:\n",
    "        cert_button = False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #STEP - 3 : All the buttons whose value is false, we extract their information\n",
    "\n",
    "    #Education  Tag\n",
    "    ed_name = []\n",
    "    ed_course = []\n",
    "    ed_year = []\n",
    "    #ed_activities=[]\n",
    "    ed_name_string = \"\" \n",
    "    ed_course_string = \"\" \n",
    "    ed_year_string = \"\"\n",
    "    if ed_button == False:\n",
    "        if ed_tag ==\"\":\n",
    "            ed_name = []\n",
    "            ed_course = []\n",
    "            ed_year = []\n",
    "            #ed_activities=[]\n",
    "        else:\n",
    "            for i in ed_tag.findAll('li', class_ = \"artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\"):\n",
    "                #Name of institute\n",
    "\n",
    "                ed_name_string += i.find('span', class_ = \"visually-hidden\").text.strip()\n",
    "                ed_name_string += \" | \"\n",
    "\n",
    "                \n",
    "                #Name of Course\n",
    "                if bool(i.find('span', class_ = \"t-14 t-normal\")) == True:\n",
    "                    ed_course_string += i.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip()\n",
    "                    ed_course_string += \" | \"\n",
    "                else:\n",
    "                    ed_course.append(\"Not Given\")\n",
    "\n",
    "                #Year of course\n",
    "                if bool(i.find('span', class_ = \"t-14 t-normal t-black--light\")) == True:\n",
    "                    ed_year_string += i.find('span', class_ = \"t-14 t-normal t-black--light\").find('span', class_ = \"visually-hidden\").text.strip()\n",
    "                    ed_year_string += \" | \"\n",
    "                else:\n",
    "                    ed_year.append(\"Not Given\")\n",
    "                \n",
    "    if bool(ed_year_string) == True:\n",
    "        ed_year.append(ed_year_string)\n",
    "\n",
    "    if bool(ed_name_string) == True:\n",
    "        ed_name.append(ed_name_string)\n",
    "\n",
    "    if bool(ed_course_string) == True:\n",
    "        ed_course.append(ed_course_string)\n",
    "\n",
    "    preCompCompiled = \"\"\n",
    "    #Experience Tag\n",
    "    curr_company = []\n",
    "    curr_yearLocation = []\n",
    "    curr_position = []\n",
    "    pre_comp = []\n",
    "    pre_yearLocation = []\n",
    "    \n",
    "    if exp_button == False:\n",
    "        if exp_tag == \"\":\n",
    "            curr_company = []\n",
    "            curr_yearLocation = []\n",
    "            curr_position = []\n",
    "            pre_comp = []\n",
    "            pre_yearLocation = []\n",
    "\n",
    "        else:\n",
    "            expTag = exp_tag.find('ul',class_ = \"pvs-list ph5 display-flex flex-row flex-wrap\").findAll('li', class_ = \"artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\")\n",
    "\n",
    "            curr = expTag[0]\n",
    "\n",
    "            #flag tells us if our company has multiple positions or single\n",
    "            flag = bool(curr.find('a', class_ = \"optional-action-target-wrapper display-flex flex-column full-width\"))\n",
    "\n",
    "            #if multiple positions exist\n",
    "            if flag:\n",
    "                curr_company.append(curr.find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                curr_yearLocation.append(curr.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                curr_position.append(curr.find('li').find('span', class_ = \"visually-hidden\").text.strip())\n",
    "            else:\n",
    "                curr_company.append(curr.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                curr_yearLocation.append(curr.find('span', class_ = \"t-14 t-normal t-black--light\").find('span', class_  =\"visually-hidden\").text.strip())\n",
    "                curr_position.append(curr.find('span', class_ = \"t-bold mr1\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "\n",
    "\n",
    "\n",
    "            #Previous companies\n",
    "            for i in expTag[1:]:\n",
    "                flag = bool(i.find('a', class_ = \"optional-action-target-wrapper display-flex flex-column full-width\"))\n",
    "\n",
    "                if flag:\n",
    "                    pre_comp.append(i.find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                    pre_yearLocation.append(i.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                else:\n",
    "                    pre_comp.append(i.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                    pre_yearLocation.append(i.find('span', class_ = \"t-14 t-normal t-black--light\").find('span', class_  =\"visually-hidden\").text.strip())\n",
    "\n",
    "            preCompCompiled = \"\"\n",
    "            for i in pre_comp:\n",
    "                preCompCompiled+=i\n",
    "                preCompCompiled+=\" |\"\n",
    "            preCompCompiled = preCompCompiled[:len(preCompCompiled)-1]\n",
    "            preYearCompiled = \"\"\n",
    "            for i in pre_yearLocation:\n",
    "                preYearCompiled+=i\n",
    "                preYearCompiled+=\" |\"\n",
    "            preYearCompiled = preYearCompiled[:len(preYearCompiled)-1]\n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "    #Now we move on to acquiring the info that is external\n",
    "\n",
    "\n",
    "    #STEP - 4 : Acquiring external data\n",
    "\n",
    "    #Experience tag\n",
    "    \n",
    "    if exp_button == True:\n",
    "        urlExp = url + \"details/experience/\"\n",
    "        browser.get(urlExp)\n",
    "        src = browser.page_source\n",
    "        soup = bs(src)\n",
    "\n",
    "        expTag = soup.find('section', class_ =\"artdeco-card ember-view pb3\").findAll('li', class_ = \"pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated\")\n",
    "\n",
    "        curr = expTag[0]\n",
    "\n",
    "        #flag tells us if our company has multiple positions or single\n",
    "        flag = bool(curr.find('a', class_ = \"optional-action-target-wrapper display-flex flex-column full-width\"))\n",
    "\n",
    "        #if multiple positions exist\n",
    "        if flag:\n",
    "            curr_company.append(curr.find('span', class_ = \"visually-hidden\").text.strip())\n",
    "            curr_yearLocation.append(curr.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "            curr_position.append(curr.find('li').find('span', class_ = \"visually-hidden\").text.strip())\n",
    "        else:\n",
    "            curr_company.append(curr.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "            curr_yearLocation.append(curr.find('span', class_ = \"t-14 t-normal t-black--light\").find('span', class_  =\"visually-hidden\").text.strip())\n",
    "            curr_position.append(curr.find('span', class_ = \"t-bold mr1\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "\n",
    "\n",
    "\n",
    "        #Previous companies\n",
    "        for i in expTag[1:]:\n",
    "            flag = bool(i.find('a', class_ = \"optional-action-target-wrapper display-flex flex-column full-width\"))\n",
    "\n",
    "            if flag:\n",
    "                pre_comp.append(i.find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                pre_yearLocation.append(i.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "            else:\n",
    "                pre_comp.append(i.find('span', class_ = \"t-14 t-normal\").find('span', class_ = \"visually-hidden\").text.strip())\n",
    "                pre_yearLocation.append(i.find('span', class_ = \"t-14 t-normal t-black--light\").find('span', class_  =\"visually-hidden\").text.strip())\n",
    "\n",
    "        preCompCompiled = \"\"\n",
    "        for i in pre_comp:\n",
    "            preCompCompiled+=i\n",
    "            preCompCompiled+=\" |\"\n",
    "        preCompCompiled = preCompCompiled[:len(preCompCompiled)-1]\n",
    "        preYearCompiled = \"\"\n",
    "        for i in pre_yearLocation:\n",
    "            preYearCompiled+=i\n",
    "            preYearCompiled+=\" |\"\n",
    "        preYearCompiled = preYearCompiled[:len(preYearCompiled)-1]\n",
    "\n",
    "\n",
    "        \n",
    "    final_dict = {\"Date of extraction\":today,\n",
    "                \"Name\": name, \n",
    "                \"Location\" : location,\n",
    "                \"Header\" : header,\n",
    "                \"About\" : about, \n",
    "                \"Companies Worked at\" : [preCompCompiled],\n",
    "                \"Previous Companies Duration\" : [preYearCompiled],\n",
    "                #\"Duration\":compYearLocation[1:], #1: because we need the current company at the top\n",
    "                #\"Companies About\" : compDescription[1:],\n",
    "                \"Current Company\":curr_company,\n",
    "                \"Current Position\": curr_position,\n",
    "                #\"Current Company About\":[compDescription[0]],\n",
    "                \"Current Duration\" : curr_yearLocation,\n",
    "                #\"Current Details\": [str(str(time_list[0]) + \",\" + str(exp_years[0]))],\n",
    "                #\"Previous Companies\": comp[1:],\n",
    "                #\"Duration\":time_list[1:],\n",
    "                #\"Experience in years\" : exp_years[1:],\n",
    "                \"Educational Institutions\": ed_name,\n",
    "                \"Course\":ed_course,\n",
    "                #\"Stream\":ed_stream,\n",
    "                \"Educational Duration\":ed_year,\n",
    "                \"Linkedin URL\": url}\n",
    "                #\"Grades\":ed_grade,\n",
    "                #\"Activity\":ed_activities}\n",
    "                #\"Projects\": projName,\n",
    "                #\"Dates\":projTime,\n",
    "                #\"SKills\":[skillCell]}\n",
    "    return(final_dict)\n",
    "\n",
    "#This function actually scraps every piece of information present in the linkedin profile, I commented the ones I dont use. You can uncomment them and also uncomment them from the final dictionary\n",
    "\n",
    "def dict_df(url):\n",
    "    x = []\n",
    "    for i in url:\n",
    "        x.append(pd.DataFrame(dict([(k,pd.Series(v,dtype='object')) for k,v in profile_scrap2(i).items()])))\n",
    "    df = x[0]\n",
    "    if len(url)>1:    \n",
    "        for i in range(1,len(url)):\n",
    "            df = df.append(x[i])\n",
    "    else:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict_df(url) #Note, this is a list of URLS as we defined in the second block\n",
    "df.to_csv('Scraper.csv', encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
